{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.batch.crud_batch.Batch at 0x7f039c2f4c10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "\n",
    "\n",
    "client.batch.configure(\n",
    "    batch_size=100,\n",
    "    dynamic=False,\n",
    "    timeout_retries=3,\n",
    "    callback=weaviate.util.check_batch_result,\n",
    "    consistency_level=weaviate.data.replication.ConsistencyLevel.ALL,  # default QUORUM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_obj = {\"class\": \"passage\", \"vectorizer\": \"text2vec-transformers\"}\n",
    "client.schema.create_class(class_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'Passage',\n",
       " 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "  'cleanupIntervalSeconds': 60,\n",
       "  'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       " 'moduleConfig': {'text2vec-transformers': {'poolingStrategy': 'masked_mean',\n",
       "   'vectorizeClassName': True}},\n",
       " 'properties': [{'dataType': ['text'],\n",
       "   'description': \"This property was generated by Weaviate's auto-schema feature on Fri May  5 21:29:13 2023\",\n",
       "   'indexFilterable': True,\n",
       "   'indexSearchable': True,\n",
       "   'moduleConfig': {'text2vec-transformers': {'skip': False,\n",
       "     'vectorizePropertyName': False}},\n",
       "   'name': 'passage',\n",
       "   'tokenization': 'word'}],\n",
       " 'replicationConfig': {'factor': 1},\n",
       " 'shardingConfig': {'virtualPerPhysical': 128,\n",
       "  'desiredCount': 1,\n",
       "  'actualCount': 1,\n",
       "  'desiredVirtualCount': 128,\n",
       "  'actualVirtualCount': 128,\n",
       "  'key': '_id',\n",
       "  'strategy': 'hash',\n",
       "  'function': 'murmur3'},\n",
       " 'vectorIndexConfig': {'skip': False,\n",
       "  'cleanupIntervalSeconds': 300,\n",
       "  'maxConnections': 64,\n",
       "  'efConstruction': 128,\n",
       "  'ef': -1,\n",
       "  'dynamicEfMin': 100,\n",
       "  'dynamicEfMax': 500,\n",
       "  'dynamicEfFactor': 8,\n",
       "  'vectorCacheMaxObjects': 1000000000000,\n",
       "  'flatSearchCutoff': 40000,\n",
       "  'distance': 'cosine',\n",
       "  'pq': {'enabled': False,\n",
       "   'bitCompression': False,\n",
       "   'segments': 0,\n",
       "   'centroids': 256,\n",
       "   'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       " 'vectorIndexType': 'hnsw',\n",
       " 'vectorizer': 'text2vec-transformers'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.schema.get(\"passage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'Get': {'Passage': [{'_additional': {'distance': 0.69266975,\n",
       "      'id': 'e04656ea-4d11-4e3a-be28-34d3e3cd4f14',\n",
       "      'vector': [-0.13605526,\n",
       "       -0.35305062,\n",
       "       0.68230677,\n",
       "       -0.77277356,\n",
       "       -1.0995371,\n",
       "       -0.48000315,\n",
       "       -0.6515379,\n",
       "       0.6029717,\n",
       "       -0.0536196,\n",
       "       -0.18245442,\n",
       "       -0.6804116,\n",
       "       -0.5405119,\n",
       "       -0.6405677,\n",
       "       0.20868714,\n",
       "       0.23363034,\n",
       "       0.30014825,\n",
       "       0.39301825,\n",
       "       0.64479864,\n",
       "       -0.18261391,\n",
       "       0.87439567,\n",
       "       0.3610479,\n",
       "       0.71831435,\n",
       "       0.2807732,\n",
       "       -0.98202753,\n",
       "       -0.19589275,\n",
       "       -1.121207,\n",
       "       -0.17648916,\n",
       "       -0.5177107,\n",
       "       0.63387245,\n",
       "       0.19702686,\n",
       "       -0.81997204,\n",
       "       0.2750283,\n",
       "       0.021586474,\n",
       "       -0.43989575,\n",
       "       -0.72645265,\n",
       "       0.64203036,\n",
       "       0.14953962,\n",
       "       -0.32458213,\n",
       "       -0.016760755,\n",
       "       -0.3329675,\n",
       "       -1.4782261,\n",
       "       1.4495848,\n",
       "       0.13901362,\n",
       "       0.35032842,\n",
       "       0.43210477,\n",
       "       -1.0380977,\n",
       "       0.14776342,\n",
       "       -0.21061042,\n",
       "       0.16228656,\n",
       "       1.2857785,\n",
       "       0.37037724,\n",
       "       -1.1142746,\n",
       "       -0.36521977,\n",
       "       0.31537628,\n",
       "       0.007913591,\n",
       "       0.37613133,\n",
       "       -1.1765743,\n",
       "       -0.05421864,\n",
       "       -0.06762491,\n",
       "       -0.4188706,\n",
       "       -0.09209328,\n",
       "       -0.6802617,\n",
       "       -1.2511417,\n",
       "       0.12828165,\n",
       "       0.010895686,\n",
       "       -0.7429863,\n",
       "       -0.26523894,\n",
       "       0.9101506,\n",
       "       0.49901125,\n",
       "       0.1277754,\n",
       "       -0.27246004,\n",
       "       -0.14037757,\n",
       "       -0.8869948,\n",
       "       -0.026365265,\n",
       "       -0.21278863,\n",
       "       -0.5438678,\n",
       "       0.49241653,\n",
       "       0.07500933,\n",
       "       -0.37028125,\n",
       "       0.16544041,\n",
       "       0.44330013,\n",
       "       -0.7168554,\n",
       "       -0.07271213,\n",
       "       -1.1763664,\n",
       "       -0.030316493,\n",
       "       0.95003664,\n",
       "       -0.50588375,\n",
       "       0.18321545,\n",
       "       -0.22734772,\n",
       "       1.0379387,\n",
       "       -0.3260793,\n",
       "       -0.7868401,\n",
       "       0.16062236,\n",
       "       -1.2913666,\n",
       "       -0.51244146,\n",
       "       -0.5960823,\n",
       "       0.5129546,\n",
       "       0.31608516,\n",
       "       -0.14387397,\n",
       "       -0.6870377,\n",
       "       -0.32618636,\n",
       "       -0.060557015,\n",
       "       0.33914402,\n",
       "       -0.29625934,\n",
       "       -0.17188507,\n",
       "       -0.10943203,\n",
       "       0.15796378,\n",
       "       -1.0476847,\n",
       "       -0.16515672,\n",
       "       -0.42926958,\n",
       "       -0.25323695,\n",
       "       -0.2564315,\n",
       "       0.5805193,\n",
       "       0.34745726,\n",
       "       -0.342703,\n",
       "       1.0254354,\n",
       "       -0.20268966,\n",
       "       0.38641137,\n",
       "       0.12979682,\n",
       "       0.40629682,\n",
       "       0.5219306,\n",
       "       0.20742354,\n",
       "       0.16035435,\n",
       "       0.038409904,\n",
       "       0.44680506,\n",
       "       0.44035983,\n",
       "       0.4323184,\n",
       "       -0.12260106]},\n",
       "     'passage': 'I am not sure about this.'}]}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query.get(\"passage\", [\"passage\"]).with_near_text(\n",
    "    {\"concepts\": [\"are you sure?\"]}\n",
    ").with_additional([\"vector\", \"distance\", \"id\"]).do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hostname': 'http://[::]:8080',\n",
       " 'modules': {'text2vec-transformers': {'passage': {'model': {'_name_or_path': './models/model',\n",
       "     'add_cross_attention': False,\n",
       "     'architectures': ['DPRContextEncoder'],\n",
       "     'attention_probs_dropout_prob': 0.1,\n",
       "     'bad_words_ids': None,\n",
       "     'begin_suppress_tokens': None,\n",
       "     'bos_token_id': None,\n",
       "     'chunk_size_feed_forward': 0,\n",
       "     'cross_attention_hidden_size': None,\n",
       "     'decoder_start_token_id': None,\n",
       "     'diversity_penalty': 0,\n",
       "     'do_sample': False,\n",
       "     'early_stopping': False,\n",
       "     'encoder_no_repeat_ngram_size': 0,\n",
       "     'eos_token_id': None,\n",
       "     'exponential_decay_length_penalty': None,\n",
       "     'finetuning_task': None,\n",
       "     'forced_bos_token_id': None,\n",
       "     'forced_eos_token_id': None,\n",
       "     'gradient_checkpointing': False,\n",
       "     'hidden_act': 'gelu',\n",
       "     'hidden_dropout_prob': 0.1,\n",
       "     'hidden_size': 768,\n",
       "     'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'},\n",
       "     'initializer_range': 0.02,\n",
       "     'intermediate_size': 3072,\n",
       "     'is_decoder': False,\n",
       "     'is_encoder_decoder': False,\n",
       "     'label2id': {'LABEL_0': 0, 'LABEL_1': 1},\n",
       "     'layer_norm_eps': 1e-12,\n",
       "     'length_penalty': 1,\n",
       "     'max_length': 20,\n",
       "     'max_position_embeddings': 512,\n",
       "     'min_length': 0,\n",
       "     'model_type': 'dpr',\n",
       "     'no_repeat_ngram_size': 0,\n",
       "     'num_attention_heads': 12,\n",
       "     'num_beam_groups': 1,\n",
       "     'num_beams': 1,\n",
       "     'num_hidden_layers': 12,\n",
       "     'num_return_sequences': 1,\n",
       "     'output_attentions': False,\n",
       "     'output_hidden_states': False,\n",
       "     'output_scores': False,\n",
       "     'pad_token_id': 0,\n",
       "     'position_embedding_type': 'absolute',\n",
       "     'prefix': None,\n",
       "     'problem_type': None,\n",
       "     'projection_dim': 128,\n",
       "     'pruned_heads': {},\n",
       "     'remove_invalid_values': False,\n",
       "     'repetition_penalty': 1,\n",
       "     'return_dict': True,\n",
       "     'return_dict_in_generate': False,\n",
       "     'sep_token_id': None,\n",
       "     'suppress_tokens': None,\n",
       "     'task_specific_params': None,\n",
       "     'temperature': 1,\n",
       "     'tf_legacy_loss': False,\n",
       "     'tie_encoder_decoder': False,\n",
       "     'tie_word_embeddings': True,\n",
       "     'tokenizer_class': None,\n",
       "     'top_k': 50,\n",
       "     'top_p': 1,\n",
       "     'torch_dtype': 'float32',\n",
       "     'torchscript': False,\n",
       "     'transformers_version': '4.27.2',\n",
       "     'type_vocab_size': 2,\n",
       "     'typical_p': 1,\n",
       "     'use_bfloat16': False,\n",
       "     'vocab_size': 30522}},\n",
       "   'query': {'model': {'_name_or_path': './models/model',\n",
       "     'add_cross_attention': False,\n",
       "     'architectures': ['DPRQuestionEncoder'],\n",
       "     'attention_probs_dropout_prob': 0.1,\n",
       "     'bad_words_ids': None,\n",
       "     'begin_suppress_tokens': None,\n",
       "     'bos_token_id': None,\n",
       "     'chunk_size_feed_forward': 0,\n",
       "     'cross_attention_hidden_size': None,\n",
       "     'decoder_start_token_id': None,\n",
       "     'diversity_penalty': 0,\n",
       "     'do_sample': False,\n",
       "     'early_stopping': False,\n",
       "     'encoder_no_repeat_ngram_size': 0,\n",
       "     'eos_token_id': None,\n",
       "     'exponential_decay_length_penalty': None,\n",
       "     'finetuning_task': None,\n",
       "     'forced_bos_token_id': None,\n",
       "     'forced_eos_token_id': None,\n",
       "     'gradient_checkpointing': False,\n",
       "     'hidden_act': 'gelu',\n",
       "     'hidden_dropout_prob': 0.1,\n",
       "     'hidden_size': 768,\n",
       "     'id2label': {'0': 'LABEL_0', '1': 'LABEL_1'},\n",
       "     'initializer_range': 0.02,\n",
       "     'intermediate_size': 3072,\n",
       "     'is_decoder': False,\n",
       "     'is_encoder_decoder': False,\n",
       "     'label2id': {'LABEL_0': 0, 'LABEL_1': 1},\n",
       "     'layer_norm_eps': 1e-12,\n",
       "     'length_penalty': 1,\n",
       "     'max_length': 20,\n",
       "     'max_position_embeddings': 512,\n",
       "     'min_length': 0,\n",
       "     'model_type': 'dpr',\n",
       "     'no_repeat_ngram_size': 0,\n",
       "     'num_attention_heads': 12,\n",
       "     'num_beam_groups': 1,\n",
       "     'num_beams': 1,\n",
       "     'num_hidden_layers': 12,\n",
       "     'num_return_sequences': 1,\n",
       "     'output_attentions': False,\n",
       "     'output_hidden_states': False,\n",
       "     'output_scores': False,\n",
       "     'pad_token_id': 0,\n",
       "     'position_embedding_type': 'absolute',\n",
       "     'prefix': None,\n",
       "     'problem_type': None,\n",
       "     'projection_dim': 128,\n",
       "     'pruned_heads': {},\n",
       "     'remove_invalid_values': False,\n",
       "     'repetition_penalty': 1,\n",
       "     'return_dict': True,\n",
       "     'return_dict_in_generate': False,\n",
       "     'sep_token_id': None,\n",
       "     'suppress_tokens': None,\n",
       "     'task_specific_params': None,\n",
       "     'temperature': 1,\n",
       "     'tf_legacy_loss': False,\n",
       "     'tie_encoder_decoder': False,\n",
       "     'tie_word_embeddings': True,\n",
       "     'tokenizer_class': None,\n",
       "     'top_k': 50,\n",
       "     'top_p': 1,\n",
       "     'torch_dtype': 'float32',\n",
       "     'torchscript': False,\n",
       "     'transformers_version': '4.27.2',\n",
       "     'type_vocab_size': 2,\n",
       "     'typical_p': 1,\n",
       "     'use_bfloat16': False,\n",
       "     'vocab_size': 30522}}}},\n",
       " 'version': '1.19.0'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_meta()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am not sure about this.\"\n",
    "\n",
    "with client.batch as batch:\n",
    "    batch.batch_size = 50\n",
    "    batch.dynamic = True\n",
    "\n",
    "    batch.add_data_object({\"passage\": text}, class_name=\"passage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'Get': {'Passage': [{'passage': 'I am not sure about this.'}]}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query.get(\"passage\", [\"passage\", \"vector\"]).do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.schema.delete_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'Passage',\n",
       " 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "  'cleanupIntervalSeconds': 60,\n",
       "  'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       " 'moduleConfig': {'text2vec-transformers': {'poolingStrategy': 'masked_mean',\n",
       "   'vectorizeClassName': True}},\n",
       " 'properties': [],\n",
       " 'replicationConfig': {'factor': 1},\n",
       " 'shardingConfig': {'virtualPerPhysical': 128,\n",
       "  'desiredCount': 1,\n",
       "  'actualCount': 1,\n",
       "  'desiredVirtualCount': 128,\n",
       "  'actualVirtualCount': 128,\n",
       "  'key': '_id',\n",
       "  'strategy': 'hash',\n",
       "  'function': 'murmur3'},\n",
       " 'vectorIndexConfig': {'skip': False,\n",
       "  'cleanupIntervalSeconds': 300,\n",
       "  'maxConnections': 64,\n",
       "  'efConstruction': 128,\n",
       "  'ef': -1,\n",
       "  'dynamicEfMin': 100,\n",
       "  'dynamicEfMax': 500,\n",
       "  'dynamicEfFactor': 8,\n",
       "  'vectorCacheMaxObjects': 1000000000000,\n",
       "  'flatSearchCutoff': 40000,\n",
       "  'distance': 'cosine',\n",
       "  'pq': {'enabled': False,\n",
       "   'bitCompression': False,\n",
       "   'segments': 0,\n",
       "   'centroids': 256,\n",
       "   'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       " 'vectorIndexType': 'hnsw',\n",
       " 'vectorizer': 'text2vec-transformers'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.schema.get(\"passage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.query.aggregate(\"Document\").with_meta_count().do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.schema.get()[\"classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_meta()[\"modules\"][\"text2vec-transformers\"].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with client.batch as batch:\n",
    "    # Add object without a custom vector.\n",
    "    # When using vectorization modules this can be used\n",
    "    # or when you don't want to set a vector\n",
    "    batch.add_data_object(\n",
    "        first_object_props, \"Author\", \"36ddd591-2dee-4e7e-a3cc-eb86d30a4303\"\n",
    "    )\n",
    "    # Add object with a custom vector\n",
    "    batch.add_data_object(\n",
    "        second_object_props,\n",
    "        \"Author\",\n",
    "        \"36ddd591-2dee-4e7e-a3cc-eb86d30a4304\",\n",
    "        vector=[0.1, 0.2, 0.3],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/covid1000/\"\n",
    "paths = [path for path in Path(data_path).glob(\"**/*.txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = convert_files_to_docs(\"data/covid1000/\", split_paragraphs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=False,\n",
    "    split_by=\"word\",\n",
    "    split_length=100,\n",
    "    split_respect_sentence_boundary=True,\n",
    ")\n",
    "docs_default = preprocessor.process(all_docs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline:\n",
    "\n",
    "1. Cleaning\n",
    "2. Split to small chunks (e.g., paragraph)\n",
    "3. Convert to documents in Haystack format\n",
    "4. Push to vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = Path(\"./data/covid1000/\")\n",
    "file_paths = [p for p in Path(file_dir).glob(\"**/*.txt\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from askem.preprocessing import TextProcessor, convert_files_to_docs\n",
    "\n",
    "tp = TextProcessor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import string\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional\n",
    "from tqdm.autonotebook import tqdm\n",
    "import nltk\n",
    "from haystack.nodes.file_converter import (\n",
    "    BaseConverter,\n",
    "    DocxToTextConverter,\n",
    "    PDFToTextConverter,\n",
    "    TextConverter,\n",
    ")\n",
    "from haystack.schema import Document\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentences(text: str) -> List[str]:\n",
    "    \"\"\"Generic text cleaning function.\"\"\"\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = [word_tokenize(sentence) for sentence in sentences]\n",
    "    words = [\n",
    "        [word.lower() for word in sentence if word not in string.punctuation]\n",
    "        for sentence in words\n",
    "    ]\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [\n",
    "        [word for word in sentence if word not in stop_words] for sentence in words\n",
    "    ]\n",
    "\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [[lemmatizer.lemmatize(word) for word in sentence] for sentence in words]\n",
    "\n",
    "    return [\" \".join(sentence) for sentence in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_paragraphs(self, text) -> str:\n",
    "    \"\"\"Separate text into paragraphs using `\\n\\n` as separator.\"\"\"\n",
    "\n",
    "    text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentences = [s for s in sentences if len(s) > self.min_characters]\n",
    "    is_continuous = self._get_is_continuous(sentences)\n",
    "\n",
    "    # Group sentences into paragraphs\n",
    "    paragraphs = [sentences[0]]\n",
    "    for i, sentence in enumerate(sentences[1:]):\n",
    "        not_too_long = len(word_tokenize(paragraphs[-1] + \" \" + sentence)) < 1024\n",
    "        if is_continuous[i] and not_too_long:\n",
    "            paragraphs[-1] += \" \" + sentence  # Append to last paragraph\n",
    "        else:\n",
    "            paragraphs.append(sentence)  # Start a new paragraph\n",
    "\n",
    "    return \"\\n\\n\".join(paragraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dir = \"data/covid1000/\"\n",
    "docs = convert_files_to_docs(\n",
    "    dir_path=doc_dir, clean_func=tp.to_paragraphs, split_paragraphs=True\n",
    ")\n",
    "\n",
    "document_store = FAISSDocumentStore(embedding_dim=128, faiss_index_factory_str=\"Flat\")\n",
    "document_store.write_documents(docs)\n",
    "retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model=\"vblagoje/dpr-question_encoder-single-lfqa-wiki\",\n",
    "    passage_embedding_model=\"vblagoje/dpr-ctx_encoder-single-lfqa-wiki\",\n",
    ")\n",
    "document_store.update_embeddings(retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Seq2SeqGenerator(model_name_or_path=\"vblagoje/bart_lfqa\")\n",
    "pipe = GenerativeQAPipeline(generator, retriever)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
