{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set creation\n",
    "\n",
    "- From `covid_qa_deepset`\n",
    "- 8-2 split, rng = 2023, test n = 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from askem.data import get_covid_qa\n",
    "\n",
    "test_data = get_covid_qa(split=\"test\")\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "petal_df = pd.read_csv(\"data/petal_bench.csv\")\n",
    "\n",
    "\n",
    "def get_petal_ans(example):\n",
    "    \"\"\"Get the answer from Petal scrape.\"\"\"\n",
    "\n",
    "    try:\n",
    "        example[\"petal_answer\"] = petal_df.query(\n",
    "            f\"id == {example['id']}\"\n",
    "        ).answer.values[0]\n",
    "    except IndexError:\n",
    "        example[\"petal_answer\"] = None\n",
    "    example[\"true_answer\"] = example[\"answers\"][\"text\"][0]\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.map(get_petal_ans)\n",
    "test_data = test_data.filter(lambda x: x[\"petal_answer\"] is not None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_parquet(\"data/petal_bench.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_bench = pd.read_parquet(\"data/petal_bench.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "\n",
    "y_true = petal_bench[\"true_answer\"].tolist()\n",
    "y_pred = petal_bench[\"petal_answer\"].tolist()\n",
    "precision, recall, f1 = score(y_true, y_pred, lang=\"en\", verbose=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to parquet for easier access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "petal_bench[\"precision\"] = precision.numpy()\n",
    "petal_bench[\"recall\"] = recall.numpy()\n",
    "petal_bench[\"f1\"] = f1.numpy()\n",
    "petal_bench.to_parquet(\"data/petal_bench.parquet\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "df = pd.read_parquet(\"data/petal_bench.parquet\")\n",
    "alt.Chart(df[[\"f1\"]]).mark_bar().encode(\n",
    "    x=alt.X(\"f1\", bin=alt.Bin()),\n",
    "    y=\"count()\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"BERT-f1 with COVID-QA: {df.f1.mean():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
