{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import weaviate\n",
    "from tqdm import tqdm\n",
    "\n",
    "from askem.ingest_docs import append_terms\n",
    "from askem.terms_extractor import MoreThanOneCapStrategy, get_blacklist\n",
    "\n",
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "WEAVIATE_APIKEY = os.getenv(\"WEAVIATE_APIKEY\")\n",
    "print(WEAVIATE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(\n",
    "    url=WEAVIATE_URL, auth_client_secret=weaviate.AuthApiKey(api_key=WEAVIATE_APIKEY)\n",
    ")\n",
    "\n",
    "schema = client.schema.get()\n",
    "client.query.aggregate(\"Passage\").with_meta_count().do()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = client.schema.get()\n",
    "all_properties = [x[\"name\"] for x in schema[\"classes\"][0][\"properties\"]]\n",
    "print(all_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a function to patch a paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_doc(client, class_name: str, doc: str) -> None:\n",
    "    \"\"\"Patch a given paragraph.\"\"\"\n",
    "\n",
    "    extractor = MoreThanOneCapStrategy(\n",
    "        min_length=3, min_occurrence=1, top_k=3, blacklist=get_blacklist(doc[\"topic\"])\n",
    "    )\n",
    "\n",
    "    # Strip old terms\n",
    "    for i in range(10):\n",
    "        doc[f\"article_terms_{i}\"] = None\n",
    "    for i in range(3):\n",
    "        doc[f\"paragraph_terms_{i}\"] = None\n",
    "\n",
    "    # Add new terms\n",
    "    docs = append_terms([doc], extractor)\n",
    "\n",
    "    # Update the data objects\n",
    "    doc = docs[0]\n",
    "    uuid = doc.pop(\"_additional\")[\"id\"]\n",
    "    _ = doc.pop(\"text_content\")\n",
    "    client.data_object.update(uuid=uuid, class_name=class_name, data_object=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_with_cursor(client, class_name, class_properties, batch_size, cursor):\n",
    "    query = (\n",
    "        client.query.get(class_name, class_properties)\n",
    "        .with_additional([\"id\"])\n",
    "        .with_limit(batch_size)\n",
    "    )\n",
    "\n",
    "    if cursor is not None:\n",
    "        return query.with_after(cursor).do()\n",
    "    else:\n",
    "        return query.do()\n",
    "\n",
    "\n",
    "def patch_all(client, batch_size: int = 5000, class_name: str = \"Passage\") -> None:\n",
    "    \"\"\"Append terms to all records.\"\"\"\n",
    "\n",
    "    cursor = None\n",
    "    progress_bar = tqdm(total=1080)\n",
    "\n",
    "    while True:\n",
    "        results = get_batch_with_cursor(\n",
    "            client,\n",
    "            class_name,\n",
    "            [\"paper_id\", \"topic\", \"text_content\", \"article_terms_0\"],\n",
    "            batch_size,\n",
    "            cursor,\n",
    "        )\n",
    "\n",
    "        # Stop if there are no more results\n",
    "        if not results[\"data\"][\"Get\"][class_name]:\n",
    "            break\n",
    "\n",
    "        objects = results[\"data\"][\"Get\"][class_name]\n",
    "        cursor = results[\"data\"][\"Get\"][class_name][-1][\"_additional\"][\"id\"]\n",
    "\n",
    "        for obj in objects:\n",
    "            if obj[\"article_terms_0\"] is None:\n",
    "                continue\n",
    "            patch_doc(client, class_name, obj)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_all(client=client)\n",
    "# 25 hours runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all are patched (article_term_0 had set to None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = None\n",
    "unpatched = []\n",
    "progress_bar = tqdm(total=1080)\n",
    "while True:\n",
    "    results = get_batch_with_cursor(\n",
    "        client, \"Passage\", [\"paper_id\", \"article_terms_0\"], 5000, cursor\n",
    "    )\n",
    "\n",
    "    # Stop if there are no more results\n",
    "    if not results[\"data\"][\"Get\"][\"Passage\"]:\n",
    "        break\n",
    "\n",
    "    objects = results[\"data\"][\"Get\"][\"Passage\"]\n",
    "    cursor = results[\"data\"][\"Get\"][\"Passage\"][-1][\"_additional\"][\"id\"]\n",
    "\n",
    "    for obj in objects:\n",
    "        if obj[\"article_terms_0\"] is not None:\n",
    "            unpatched.append(obj)\n",
    "\n",
    "    progress_bar.update(1)\n",
    "progress_bar.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
