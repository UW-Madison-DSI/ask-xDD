{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Testset and Just look at the results\n",
    "\n",
    "Procedure summary:\n",
    "1. Get article and paragraph level capitalized terms\n",
    "2. Append top 10 `terms` and top 3 `terms` to the item's metadata in the vector store\n",
    "3. Use Hackathon testset to compare 2 new search strategies (article level and paragraph level `term` filtering + embedding search) \n",
    "\n",
    "Findings:\n",
    "1. New term filtering strategy is better than the old one in some cases\n",
    "2. Paragraph level term filtering is better than article level term filtering in some cases\n",
    "3. Have to address missing terms\n",
    "    - `SpaCy` proper nouns?\n",
    "    - Words that contains multiple capitalized letters\n",
    "    - Allow hyphenated words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import requests\n",
    "from typing import List, Optional\n",
    "from askem.preprocessing import get_all_cap_words\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_testset() -> pd.DataFrame:\n",
    "    \"\"\"Load testset from Google Sheet.\"\"\"\n",
    "\n",
    "    GCP_SECRET_FILE_PATH = os.getenv(\"GCP_SECRET_FILE_PATH\")\n",
    "\n",
    "    gc = gspread.service_account(filename=GCP_SECRET_FILE_PATH)\n",
    "    sheet = gc.open(\"ASKEM-TA1-testset\").worksheet(\"questions\")\n",
    "\n",
    "    records = sheet.get_values()\n",
    "    labels = records[0]\n",
    "    data = records[1:]\n",
    "\n",
    "    new_labels = [label.lower().replace(\" \", \"_\") for label in labels]\n",
    "    df = pd.DataFrame.from_records(data, columns=new_labels)\n",
    "    return df[[\"source\", \"target_type\", \"is_keyword\", \"question\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_testset()\n",
    "df[\"terms\"] = df[\"question\"].apply(get_all_cap_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"terms\", \"is_keyword\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we should not include some really common terms like: `COVID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST_COMMON_TERMS = [\"COVID19\", \"COVID\"]\n",
    "\n",
    "\n",
    "def get_better_terms(text: str, blacklist: Optional[List[str]] = None) -> List[str]:\n",
    "    \"\"\"Get better terms from text.\"\"\"\n",
    "    terms = get_all_cap_words(text)\n",
    "    if not terms:\n",
    "        return None\n",
    "\n",
    "    if blacklist is None:\n",
    "        blacklist = BLACKLIST_COMMON_TERMS\n",
    "\n",
    "    better_terms = [term for term in terms if term not in blacklist]\n",
    "    if not better_terms:\n",
    "        return None\n",
    "    return better_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"terms\"] = df[\"question\"].apply(get_better_terms)\n",
    "df[[\"terms\", \"is_keyword\", \"question\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note. `COmplexVID` is not considered as a term. TODO: May need to address this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ta1(\n",
    "    question: str, article_terms: List[str] = None, paragraph_terms: List[str] = None\n",
    ") -> List[dict]:\n",
    "    \"\"\"Evaluate a question using the retriever API.\"\"\"\n",
    "\n",
    "    URL = os.getenv(\"RETRIEVER_URL\")\n",
    "    APIKEY = os.getenv(\"RETRIEVER_APIKEY\")\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Api-Key\": APIKEY}\n",
    "    json = {\"question\": question, \"top_k\": 3, \"doc_type\": \"paragraph\"}\n",
    "\n",
    "    if article_terms:\n",
    "        json[\"article_terms\"] = article_terms\n",
    "\n",
    "    if paragraph_terms:\n",
    "        json[\"paragraph_terms\"] = paragraph_terms\n",
    "\n",
    "    response = requests.post(URL, headers=headers, json=json)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all questions with terms\n",
    "\n",
    "df_with_terms = df.query(\"terms.notnull()\")\n",
    "\n",
    "results = []\n",
    "for row in df_with_terms.itertuples():\n",
    "    results.append(\n",
    "        {\n",
    "            \"question\": row.question,\n",
    "            \"terms\": row.terms,\n",
    "            \"results_original\": eval_ta1(row.question),\n",
    "            \"results_with_article_level_filter\": eval_ta1(\n",
    "                row.question, article_terms=row.terms\n",
    "            ),\n",
    "            \"results_with_paragraph_level_filter\": eval_ta1(\n",
    "                row.question, paragraph_terms=row.terms\n",
    "            ),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a proper df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(result: dict) -> dict:\n",
    "    \"\"\"Flatten and select results.\"\"\"\n",
    "\n",
    "    output = {\n",
    "        \"question\": result[\"question\"],\n",
    "        \"terms\": result[\"terms\"],\n",
    "        \"original_top_1\": result[\"results_original\"][0][\"text\"],\n",
    "        \"original_top_2\": result[\"results_original\"][1][\"text\"],\n",
    "        \"original_top_3\": result[\"results_original\"][2][\"text\"],\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        output[\"article_top_1\"] = result[\"results_with_article_level_filter\"][0][\"text\"]\n",
    "        output[\"article_top_2\"] = result[\"results_with_article_level_filter\"][1][\"text\"]\n",
    "        output[\"article_top_3\"] = result[\"results_with_article_level_filter\"][2][\"text\"]\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        output[\"paragraph_top_1\"] = result[\"results_with_paragraph_level_filter\"][0][\n",
    "            \"text\"\n",
    "        ]\n",
    "        output[\"paragraph_top_2\"] = result[\"results_with_paragraph_level_filter\"][1][\n",
    "            \"text\"\n",
    "        ]\n",
    "        output[\"paragraph_top_3\"] = result[\"results_with_paragraph_level_filter\"][2][\n",
    "            \"text\"\n",
    "        ]\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_records([flatten(result) for result in results])\n",
    "df_results.to_csv(\"ta1_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results moved to [shared drive](https://docs.google.com/spreadsheets/d/1TJjtPoCaxIWaMDR_yTDka72uzOglDJis-hxNU78b9AA/edit#gid=95932881) for manual examination."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
